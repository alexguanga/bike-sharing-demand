{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Update the modeling function. for some weird reason, the cross validation seems to be a weird one\n",
    "# Since we are adding a function (\"make_scorer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from ml_metrics import rmsle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets that will be used\n",
    "\n",
    "training_set = pd.read_csv(\"./archive/train.csv\", parse_dates=True)\n",
    "testing_set = pd.read_csv(\"./archive/test.csv\", parse_dates=True)\n",
    "train_test_set = pd.concat([training_set, testing_set], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set['count_log'] = np.log(train_test_set['count']+1)\n",
    "train_test_set['casual_log'] = np.log(train_test_set['casual']+1)\n",
    "train_test_set['registered_log'] = np.log(train_test_set['registered']+1)\n",
    "train_test_set['is_test'] = train_test_set['count'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_vars(data, unwanted_list):\n",
    "    feats = [feat for feat in data.columns if feat not in unwanted_list]\n",
    "    return feats\n",
    "\n",
    "def get_Xs_y(data, unwanted_list, target='count'):\n",
    "    feats = remove_unwanted_vars(data, unwanted_list)\n",
    "    return data[feats].values, data[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following are the functions that can expediate the code\n",
    "def rmsle_custom(actual, predicted):\n",
    "    sle = (np.power(np.log(np.array((actual))+1) - \n",
    "            np.log(np.array(np.abs(predicted))+1), 2))\n",
    "    msle = np.mean(sle)\n",
    "    return (np.sqrt(msle))\n",
    "\n",
    "def regression_models(fitted_model, Xs, y, cv=10):\n",
    "    rmsle_score = make_scorer(rmsle_custom, greater_is_better=False)\n",
    "    model_score = cross_val_score(fitted_model, Xs.values, y.values, cv=cv, scoring=rmsle_score)\n",
    "    return np.abs(np.mean(model_score))\n",
    "\n",
    "def return_parameters(gridsearch, verbose=False):\n",
    "    params = gridsearch.best_params_\n",
    "    accuracy = gridsearch.best_score_\n",
    "    if verbose:\n",
    "        print('{0} were the best parameters to use'.format(params))\n",
    "        print('{0} was the accuracies'.format(np.abs(accuracy)))\n",
    "    return [params, np.abs(accuracy)]\n",
    "\n",
    "def gridsearch_cv(model, params, cv_iters, X, y):\n",
    "    rmsle_score = make_scorer(rmsle_custom, greater_is_better=False)\n",
    "    grid_search = GridSearchCV(estimator=model(),\n",
    "                               param_grid=params,\n",
    "                               scoring=rmsle_score,\n",
    "                               cv=2, n_jobs=-1)\n",
    "    fitted_model = grid_search.fit(X, y)\n",
    "    return fitted_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noticed that we have date that can be parsed in many ways\n",
    "\n",
    "def feature_enginering(data):\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['day'] = data['datetime'].dt.day\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['minute'] = data['datetime'].dt.minute\n",
    "    data['dayofweek'] = data['datetime'].dt.dayofweek\n",
    "    data['weekofyear'] = data['datetime'].dt.weekofyear\n",
    "\n",
    "    data['weekend'] = data['dayofweek'].map(lambda x: int(x in [5,6]))\n",
    "\n",
    "    # Conditional on time of day, morning=1, afternoon=2, evening=3, night=4\n",
    "    conditions = [\n",
    "        ((data['hour'] >=  5) & (data['hour'] < 12)),\n",
    "        ((data['hour'] >=  12) & (data['hour'] < 17)),\n",
    "        ((data['hour'] >=  17) & (data['hour'] < 21))\n",
    "    ]\n",
    "    choices = [1, 2, 3]\n",
    "    data['time_of_day'] = np.select(conditions, choices, default=4)\n",
    "\n",
    "\n",
    "    data['rush_hour'] = training_set['hour'].apply(lambda x: int(x in [8,9,10,17,18,19]))\n",
    "    data['rush_workday'] = 0\n",
    "    data.loc[data['weekend'] == 0, 'rush_workday'] = 1\n",
    "    \n",
    "    \n",
    "    data['holiday'] = data[['month', 'day', 'holiday', 'year']].apply(\n",
    "        lambda x: (x['holiday'], 1)[x['year'] == 2012 and x['month'] == 10 and (x['day'] in [30])], axis = 1)\n",
    "\n",
    "    data['holiday'] = data[['month', 'day', 'holiday']].apply(\n",
    "        lambda x: (x['holiday'], 1)[x['month'] == 12 and (x['day'] in [24, 26, 31])], axis = 1)\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the BikeAnalysis: I will check the performance of the 15-variable feature selection\n",
    "\n",
    "features_1 = ['season', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', \n",
    "              'month', 'day', 'hour', 'dayofweek', 'weekofyear', 'time_of_day', 'rush_hour']\n",
    "features_xgb = ['season','holiday','workingday','weather','temp','atemp','humidity', 'windspeed',\n",
    "                'year','month','hour','dayofweek','weekofyear','time_of_day','rush_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One good method will be to compute the count, registered, and casual\n",
    "\n",
    "y_count = training_set['count'].astype(float)\n",
    "y_reg = training_set['casual'].astype(float)\n",
    "y_cas = training_set['registered'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexguanga/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "/Users/alexguanga/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    }
   ],
   "source": [
    "training_set = feature_enginering(training_set)\n",
    "Xs, y = training_set[features_1], training_set['count'].astype(float)\n",
    "y_reg, y_cas = training_set['registered'], training_set['casual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From Analysis, we found the extra_tree is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor\n",
    "# Learning rate: .5, min_samples_split=5, loss=lad, max_depth=5, max_depth=6\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [1000,2000,3000,4000],\n",
    "    'max_features': [\"auto\",\"sqrt\",\"log2\",0.6,0.8],\n",
    "    'min_samples_leaf':[30,40,50,60,70],\n",
    "    'min_samples_split':[150,200,250,300],\n",
    "    'max_depth' : [10,15,20,25],\n",
    "    'subsample': [0.4,0.6,0.8],\n",
    "    'learning_rate':[0.1,0.01,0.001]\n",
    "}\n",
    "\n",
    "gridcv_gradboost = gridsearch_cv(GradientBoostingRegressor, params, 10, Xs, y)\n",
    "return_parameters(gridcv_gradboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predicted and actual are using the absolute values\n",
    "    - 0.6785850210551115\n",
    "- actual is absolute values\n",
    "    - nan\n",
    "- Predicted is absolute values\n",
    "    - 0.6799188779582174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6863817055451075"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model with the best parameters\n",
    "\n",
    "gbm_params = {\n",
    "    'n_estimators': 50, 'max_depth': 6, 'random_state': 0, 'min_samples_split': 5, \n",
    "    'learning_rate': 0.5, 'loss': 'lad'\n",
    "}\n",
    "\n",
    "gbm_model = GradientBoostingRegressor(**gbm_params)\n",
    "gbm_model_mean = regression_models(gbm_model, Xs, y)\n",
    "\n",
    "gbm_model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50} were the best parameters to use\n",
      "-0.5868346520967258 was the accuracies\n"
     ]
    }
   ],
   "source": [
    "# Xgboost Regressor\n",
    "# Grid Search Step 1 -> max_depth = 5, learning_rate=.1, n_estimators=50\n",
    "\n",
    "# Using a new set of features\n",
    "# accuracy was .58 with \"features_1\"\n",
    "\n",
    "xgboost_params = {\n",
    "    'max_depth': [7,8,9], 'learning_rate': [.1], \n",
    "    'n_estimators': [50]\n",
    "}\n",
    "\n",
    "# gridcv_xgboost = gridsearch_cv(xgb.XGBRegressor, xgboost_params, 10, Xs, y)\n",
    "gridcv_xgboost = gridsearch_cv(xgb.XGBRegressor, xgboost_params, 10, training_set[features_xgb], y)\n",
    "return_parameters(gridcv_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5867960084359407"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model with the best parameters\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 7, 'learning_rate': .1, 'random_state': 0, 'n_estimators': 50\n",
    "}\n",
    " \n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model_mean = regression_models(xgb_model, Xs, y)\n",
    "xgb_model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model_mean_cas->-0.6851131606707945\n",
    "# xgb_model_mean_cas->-0.6489501931980225\n",
    "# xgb_model_mean->-0.6195904516161043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 9,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 4,\n",
       "  'n_estimators': 30},\n",
       " 0.5382425911023736]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extratree regressor\n",
    "\n",
    "extratree_parms = {\n",
    "    'n_estimators': [10,20,30], 'max_depth': [5,7,9], 'min_samples_split': [2,4,6],\n",
    "    'min_samples_leaf': [1,3,5], 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "gridcv_extratrees = gridsearch_cv(ExtraTreesRegressor, extratree_parms, 10, Xs, y)\n",
    "return_parameters(gridcv_extratrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5434157102695787"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model with the best parameters\n",
    "\n",
    "extratree_params = {'max_depth': 9, 'max_features': 'auto', 'min_samples_leaf': 1, \n",
    "              'min_samples_split': 4, 'n_estimators': 20}\n",
    " \n",
    "extratree_model = ExtraTreesRegressor(**extratree_params)\n",
    "extratree_model_mean = regression_models(extratree_model, Xs, y)\n",
    "extratree_model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.188031413451893, 0.811968586548107)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does splitting the data btw casual and registered make any differenced (what is the average split?)\n",
    "# It does not! (atleast using the analysis)\n",
    "\n",
    "sum_count = sum(training_set['count'])\n",
    "sum_casual = sum(training_set['casual'])\n",
    "sum_registered = sum(training_set['registered'])\n",
    "\n",
    "sum_casual/sum_count, sum_registered/sum_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = feature_enginering(testing_set)\n",
    "xgb_model = xgb_model.fit(training_set[features_1], training_set['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions\n",
    "predict = xgb_model.predict(testing_set[features_1])\n",
    "predict[predict < 0] = 1.5\n",
    "testing_set['count'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set[['datetime', 'count']].to_csv('final_submit_6.30.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
